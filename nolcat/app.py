import io
from pathlib import Path
from datetime import datetime
import json
import re
from flask import Flask
from flask import render_template
from flask import send_file
import botocore.exceptions  # `botocore` is a dependency of `boto3`

from .logging_config import *
from .nolcat_glue_job import *
from .statements import *

log = logging.getLogger(__name__)


def page_not_found(error):
    """Returns the 404 page when a HTTP 404 error is raised."""
    return render_template('404.html'), 404


def internal_server_error(error):
    """Returns the 500 page when a HTTP 500 error is raised."""
    return render_template('500.html', error=error), 500  #ToDo: This doesn't seem to be working; figure out why


def create_app():
    """A factory pattern for instantiating Flask web apps."""
    log.info("Starting `create_app()`.")
    app = Flask(__name__)
    app.register_error_handler(404, page_not_found)
    app.register_error_handler(500, internal_server_error)
    app.config['SQLALCHEMY_DATABASE_URI'] = f'mysql://{DATABASE_USERNAME}:{DATABASE_PASSWORD}@{DATABASE_HOST}:{DATABASE_PORT}/{DATABASE_SCHEMA_NAME}'
    app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False  # Explicitly set to disable warning in tests
    app.config['SQLALCHEMY_ECHO'] = False  # This prevents SQLAlchemy from duplicating the log output generated by `nolcat.app.configure_logging()`
    app.config['SECRET_KEY'] = SECRET_KEY
    app.config['UPLOAD_FOLDER'] = './static'  # This config is never invoked because Flask alone is never used for file I/O.
    # OR app.config['UPLOAD_FOLDER'] = './relation_initialization_templates'  # This config sets the file that handles both Flask file downloads and uploads, but since all input, including file uploads, is handled with WTForms, this folder is only used for storing content the user will need to download.
    csrf.init_app(app)
    db.init_app(app)
    configure_logging(app)

    #Section: Create Command to Build Schema
    # Documentation for decorator at https://flask.palletsprojects.com/en/2.1.x/appcontext/
    @app.cli.command('create-db')
    def create_db():
        with create_app().app_context():  # Creates an app context using the Flask factory pattern
            # Per instructions at https://flask-sqlalchemy.palletsprojects.com/en/2.x/quickstart/: "To create the initial database, just import the db object[s]...and run the `SQLAlchemy.create_all()` method"
            from .models import FiscalYears
            from .models import AnnualStatistics
            from .models import Vendors
            from .models import VendorNotes
            from .models import StatisticsSources
            from .models import StatisticsSourceNotes
            from .models import ResourceSources
            from .models import ResourceSourceNotes
            from .models import StatisticsResourceSources
            from .models import AnnualUsageCollectionTracking
            from .models import COUNTERData
            db.create_all()

    #Section: Register Blueprints
    try:
        from nolcat import annual_stats
    except:
        from . import annual_stats
    app.register_blueprint(annual_stats.bp)

    try:
        from nolcat import ingest_usage
    except:
        from . import ingest_usage
    app.register_blueprint(ingest_usage.bp)

    try:
        from nolcat import initialization
    except:
        from . import initialization
    app.register_blueprint(initialization.bp)

    try:
        from nolcat import login
    except:
        from . import login
    app.register_blueprint(login.bp)

    try:
        from nolcat import view_lists
    except:
        from . import view_lists
    app.register_blueprint(view_lists.bp)

    try:
        from nolcat import view_usage
    except:
        from . import view_usage
    app.register_blueprint(view_usage.bp)

    #Section: Create Basic Routes
    @app.route('/')
    def homepage():
        """Returns the homepage in response to web app root requests."""
        return render_template('index.html')
    
    
    @app.route('/download/<path:file_path>',  methods=['GET', 'POST'])
    def download_file(file_path):
        """Downloads the file at the absolute file path in the variable route.

        This function allows static files to be downloaded in Jinja templates (redirecting to this route function from other route functions raises a ValueError in pytest). An absolute file path is used to ensure that issues of relative locations and changing current working directories don't cause errors.

        Args:
            file_path (str): an absolute file path
        
        Returns:
            file: a file is downloaded to the host machine through the web application
        """
        log.info(f"Starting `create_app.download_file()` for file at path {file_path} (type {type(file_path)}).")
        file_path = Path(  # Just using the `Path()` constructor creates a relative path; relative paths in `send_file()` are considered in relation to CWD
            TOP_NOLCAT_DIRECTORY,
            *Path(file_path).parts[Path(file_path).parts.index('nolcat')+1:],  # This creates a path from `file_path` with everything after the initial `nolcat` folder
        )
        log.info(f"`file_path` after type juggling is '{file_path}' (type {type(file_path)}) which is an absolute file path: {file_path.is_absolute()}.")
        return send_file(
            path_or_file=file_path,
            mimetype=file_extensions_and_mimetypes()[file_path.suffix],  # Suffixes that aren't keys in `file_extensions_and_mimetypes()` can't be uploaded to S3 via NoLCAT
            as_attachment=True,
            download_name=file_path.name,
            last_modified=datetime.today(),
        )


    return app


def upload_file_to_S3_bucket(file, file_name, bucket_path=PATH_WITHIN_BUCKET):
    """The function for uploading files to a S3 bucket.

    SUSHI pulls that cannot be loaded into the database for any reason are saved to S3 with a file name following the convention "{statistics_source_ID}_{report path with hyphen replacing slash}_{date range start in 'yyyy-mm' format}_{date range end in 'yyyy-mm' format}_{ISO timestamp}". Non-COUNTER usage files use the file naming convention "{statistics_source_ID}_{fiscal_year_ID}".

    Args:
        file (file-like or path-like object): the file being uploaded to the S3 bucket or the path to said file as a Python object
        file_name (str): the name the file will be saved under in the S3 bucket
        bucket_path (str, optional): the path within the bucket where the files will be saved; default is constant initialized at the beginning of this module
    
    Returns:
        str: the logging statement to indicate if uploading the data succeeded or failed
    """
    log.info(f"Starting `upload_file_to_S3_bucket()` for the file named {file_name} and S3 location `{BUCKET_NAME}/{bucket_path}`.")
    #Section: Confirm Bucket Exists
    # The canonical way to check for a bucket's existence and the user's privilege to access it
    try:
        check_for_bucket = s3_client.head_bucket(Bucket=BUCKET_NAME)
    except botocore.exceptions.ClientError as error:
        message = f"Unable to upload files to S3 because the check for the S3 bucket designated for downloads raised the error {error}."
        log.error(message)
        return message
 

    #Section: Upload File to Bucket
    log.debug(f"Loading object {file} (type {type(file)}) with file name `{file_name}` into S3 location `{BUCKET_NAME}/{bucket_path}`.")
    #Subsection: Upload File with `upload_fileobj()`
    try:
        file_object = open(file, 'rb')
        log.debug(f"Successfully initialized {file_object} (type {type(file_object)}).")
        try:
            s3_client.upload_fileobj(
                Fileobj=file_object,
                Bucket=BUCKET_NAME,
                Key=bucket_path + file_name,
            )
            file_object.close()
            message = f"Successfully loaded the file {file_name} into S3 location `{BUCKET_NAME}/{bucket_path}`."
            log.info(message)
            return message
        except Exception as error:
            log.warning(f"Running the function `upload_fileobj()` on {file_object} (type {type(file_object)}) raised the error {error}. The system will now try to use `upload_file()`.")
            file_object.close()
    except Exception as error:
        log.warning(f"Running the function `open()` on {file} (type {type(file)}) raised the error {error}. The system will now try to use `upload_file()`.")
    
    #Subsection: Upload File with `upload_file()`
    try:
        if file.is_file():
            try:
                s3_client.upload_file(  # This uploads `file` like a path-like object
                    Filename=file,
                    Bucket=BUCKET_NAME,
                    Key=bucket_path + file_name,
                )
                message = f"Successfully loaded the file {file_name} into S3 location `{BUCKET_NAME}/{bucket_path}`."
                log.info(message)
                return message
            except Exception as error:
                message = f"Unable to load file {file} (type {type(file)}) into an S3 bucket because {error}."
                log.error(message)
                return message
        else:
            message = f"Unable to load file {file} (type {type(file)}) into an S3 bucket because {file} didn't point to an existing regular file."
            log.error(message)
            return message
    except AttributeError as error:
        message = f"Unable to load file {file} (type {type(file)}) into an S3 bucket because it relied on the ability for {file} to be a file-like or path-like object."
        log.error(message)
        return message


def save_unconverted_data_via_upload(data, file_name_stem, bucket_path=PATH_WITHIN_BUCKET):
    """A wrapper for the `upload_file_to_S3_bucket()` when saving SUSHI data that couldn't change data types when needed.

    Data going into the S3 bucket must be saved to a file because `upload_file_to_S3_bucket()` takes file-like objects or path-like objects that lead to file-like objects. These files have a specific naming convention, but the file name stem is an argument in the function call to simplify both this function and its testing.

    Args:
        data (dict or str): the data to be saved to a file in S3
        file_name_stem (str): the stem of the name the file will be saved with in S3
        bucket_path (str, optional): the path within the bucket where the files will be saved; default is constant initialized at the beginning of this module
    
    Returns:
        str: a message indicating success or including the error raised by the attempt to load the data
    """
    log.info(f"Starting `save_unconverted_data_via_upload()` for the file named {file_name_stem} and S3 location `{BUCKET_NAME}/{bucket_path}`.")

    #Section: Create Temporary File
    #Subsection: Create File Path
    if isinstance(data, dict):
        temp_file_name = 'temp.json'
    else:
        temp_file_name = 'temp.txt'
    temp_file_path = TOP_NOLCAT_DIRECTORY / temp_file_name
    temp_file_path.unlink(missing_ok=True)
    log.info(f"Contents of `{TOP_NOLCAT_DIRECTORY}` after `unlink()` at start of `save_unconverted_data_via_upload()`:\n{format_list_for_stdout(TOP_NOLCAT_DIRECTORY.iterdir())}")

    #Subsection: Save File
    if temp_file_name == 'temp.json':
        try:
            with open(temp_file_path, 'wb') as file:
                log.debug(f"About to write bytes JSON `data` (type {type(data)}) to file object {file}.")  #AboutTo
                json.dump(data, file)
            log.debug(f"Data written as bytes JSON to file object {file}.")
        except Exception as TypeError:
            with open(temp_file_path, 'wt') as file:
                log.debug(f"About to write text JSON `data` (type {type(data)}) to file object {file}.")  #AboutTo
                file.write(json.dumps(data))
                log.debug(f"Data written as text JSON to file object {file}.")
    else:
        try:
            with open(temp_file_path, 'wb') as file:
                log.debug(f"About to write bytes `data` (type {type(data)}) to file object {file}.")  #AboutTo
                file.write(data)
                log.debug(f"Data written as bytes to file object {file}.")
        except Exception as binary_error:
            try:
                with open(temp_file_path, 'wt', encoding='utf-8', errors='backslashreplace') as file:
                    log.debug(f"About to write text `data` (type {type(data)}) to file object {file}.")  #AboutTo
                    file.write(data)
                    log.debug(f"Data written as text to file object {file}.")
            except Exception as text_error:
                message = f"Writing data into a binary file raised the error {binary_error}; writing that data into a text file raised the error {text_error}."
                log.error(message)
                return message
    log.debug(f"File at {temp_file_path} successfully created.")

    #Section: Upload File to S3
    file_name = file_name_stem + temp_file_path.suffix
    log.debug(f"About to upload file '{file_name}' from temporary file location {temp_file_path} to S3 location `{BUCKET_NAME}/{bucket_path}`.")
    logging_message = upload_file_to_S3_bucket(
        temp_file_path,
        file_name,
        bucket_path=bucket_path,
    )
    log.info(f"Contents of `{TOP_NOLCAT_DIRECTORY}` before `unlink()` at end of `save_unconverted_data_via_upload()`:\n{format_list_for_stdout(TOP_NOLCAT_DIRECTORY.iterdir())}")
    temp_file_path.unlink()
    log.info(f"Contents of `{TOP_NOLCAT_DIRECTORY}` after `unlink()` at end of `save_unconverted_data_via_upload()`:\n{format_list_for_stdout(TOP_NOLCAT_DIRECTORY.iterdir())}")
    if isinstance(logging_message, str) and re.fullmatch(r'Running the function `.+\(\)` on .+ \(type .+\) raised the error .+\.', logging_message):
        message = f"Uploading the file {file_name} to S3 failed because {logging_message[0].lower()}{logging_message[1:]}"
        log.critical(message)
    else:
        message = logging_message
        log.debug(message)
    return message