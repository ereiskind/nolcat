"""This module contains the fixtures and configurations for testing.

The fixtures for connecting to the database are primarily based upon the fixtures at https://github.com/alysivji/flask-family-tree-api/blob/master/tests/conftest.py with some further modifications based on the code at https://spotofdata.com/flask-testing/. The test data is a small subset of the institution's own data, with usage numbers changes for confidentiality, with items selected to contain as many edge cases as possible. All test data is stored in dataframes in other files to remove encoding issues that might arise when reading data in from a tabular file but still allow the data to be exported to a tabular file.
"""

import pytest
import logging
from pathlib import Path
from datetime import date
import calendar
from random import choice
import re
import html
from sqlalchemy import create_engine
import pandas as pd
from dateutil.relativedelta import relativedelta  # dateutil is a pandas dependency, so it doesn't need to be in requirements.txt
import botocore.exceptions  # `botocore` is a dependency of `boto3`

from nolcat.app import db as _db  # `nolcat.app` imports don't use wildcard because of need for alias here
from nolcat.app import create_app
from nolcat.app import configure_logging
from nolcat.app import s3_client
from nolcat.app import DATABASE_USERNAME, DATABASE_PASSWORD, DATABASE_HOST, DATABASE_PORT, DATABASE_SCHEMA_NAME, BUCKET_NAME, PATH_WITHIN_BUCKET_FOR_TESTS
from nolcat.models import *
from nolcat.statements import *
from nolcat.SUSHI_call_and_response import *
from data import relations

log = logging.getLogger(__name__)


#Section: Fixtures for Connecting to the Database
@pytest.fixture(scope='session')
def engine():
    """Creates a SQLAlchemy engine for testing.
    
    The engine object is the starting point for an SQLAlchemy application. Engines are a crucial intermediary object in how SQLAlchemy connects the user and the database.

    Yields:
        sqlalchemy.engine.Engine: a SQLAlchemy engine
    """
    engine = create_engine(
        f'mysql://{DATABASE_USERNAME}:{DATABASE_PASSWORD}@{DATABASE_HOST}:{DATABASE_PORT}/{DATABASE_SCHEMA_NAME}',
        echo=False,  # Logging configuration includes SQLAlchemy engine, so `True` causes repetition
    )
    log.info(f"`tests.conftest.engine()` yields {engine} (type {type(engine)}).")
    yield engine


@pytest.fixture(scope='session')
def app():
    """Creates an instance of the Flask object for the test session.
    
    This instance of the Flask object includes the application context (https://flask.palletsprojects.com/en/2.0.x/appcontext/) and thus access to application-level data, such as configurations, logging, and the database connection.

    Yields:
        flask.Flask: a Flask object
    """
    app = create_app()
    app.debug = True
    app.testing = True  # Lets exceptions come through to test client
    app.env = 'test'
    app.config['SQLALCHEMY_DATABASE_URI'] = f'mysql://{DATABASE_USERNAME}:{DATABASE_PASSWORD}@{DATABASE_HOST}:{DATABASE_PORT}/{DATABASE_SCHEMA_NAME}'
    app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False  # Explicitly set to disable warning in tests
    app.config['SQLALCHEMY_ECHO'] = False  # This prevents SQLAlchemy from duplicating the log output generated by `nolcat.app.configure_logging()`
    app.config['WTF_CSRF_ENABLED'] = False  # Without this, tests involving forms return a HTTP 400 error with the message `The CSRF token is missing.`
    configure_logging(app)
    context = app.app_context()
    context.push()  # Binds the application context to the current context/Flask application
    log.info(f"`tests.conftest.app()` yields {app} (type {type(app)}), which is bound to `context` {context} (type {type(context)}).")
    yield app
    context.pop()  # Removes and deletes the application context; placement after the yield statement means the action occurs at the end of the session
    log.info("`tests.conftest.app()` teardown complete.")


@pytest.fixture(scope='session')
def client(app):
    """Creates an instance of the Flask test client.
    
    The Flask test client lets tests make HTTP requests without running the server. This fixture is used whenever a test function calls a function in the `nolcat/nolcat` folder that requires database interaction; without this fixture, the error `RuntimeError: No application found.` is raised (using the test client as a solution for this error comes from https://stackoverflow.com/a/67314104). The test client uses HTTP methods for the method names, just like requests, but such methods are actually wrappers for `werkzeug.test.Client.open()` (https://werkzeug.palletsprojects.com/en/3.0.x/test/#werkzeug.test.Client.open).

    Args:
        app (flask.Flask): a Flask object

    Yields:
        flask.testing.FlaskClient: a way to test HTTP calls without running a live server
    """
    client = app.test_client()
    log.info(f"`tests.conftest.client()` yields {client} (type {type(client)}).")
    yield client


@pytest.fixture(scope="session")
def db(app):
    """Creates a temporary copy of the database for testing.
    
    The variable of the first statement, `_db.app`, is the Flask-SQLAlchemy integration's attribute for the Flask application (context). As a result, the fixture's first statement connects the Flask-SQLAlchemy integration to the Flask application (context) being used for testing. #ALERT: This fixture is used later in this module, but not in any tests.
    """
    #ToDo: Recreate with the sources below
    # https://github.com/alysivji/flask-family-tree-api/blob/master/tests/conftest.py as initial template
    # https://testdriven.io/blog/flask-pytest/
    # http://alexmic.net/flask-sqlalchemy-pytest/ with modifications at https://stackoverflow.com/q/28526781
    # https://spotofdata.com/flask-testing/
    # https://www.appsloveworld.com/coding/flask/3/rollback-many-transactions-between-tests-in-flask
    pass


@pytest.fixture(scope='module')
def session(engine, db):
    """Creates a database session for each test module, enabling CRUD transactions, then rolling all of them back once the module's tests are complete.
    
    First, the scope of the fixture is set to `module` because a scope of `function` would prohibit tests involving primary and foreign key relationships from using data loaded into the database during previous transactions, a more accurate reflection of actual database use. On the other hand, setting the scope to `session` would disallow the reuse of the test data, as loading test data sets multiple times would cause primary key duplication. Second, this fixture instantiates both database connection objects provided by SQLAlchemy. The connection object, used in SQLAlchemy Core and the SQL language, and the session object, used by the SQLAlchemy ORM, are both offered so the fixture can work with tests using the core or the ORM paradigm. The two objects are connected--session objects use connection objects as part of the database connection, and the fixture's session object explicitly uses its connection object. #ALERT: This fixture isn't used anywhere.
    """
    #ToDo: Recreate with the sources below
    # https://github.com/alysivji/flask-family-tree-api/blob/master/tests/conftest.py as initial template
    # https://testdriven.io/blog/flask-pytest/
    # http://alexmic.net/flask-sqlalchemy-pytest/ with modifications at https://stackoverflow.com/q/28526781
    # https://spotofdata.com/flask-testing/
    # https://www.appsloveworld.com/coding/flask/3/rollback-many-transactions-between-tests-in-flask
    pass


#Section: Test Data for Relations
@pytest.fixture(scope='session')
def fiscalYears_relation():
    """Creates a dataframe that can be loaded into the `fiscalYears` relation.
    
    Yields:
        dataframe: a relation of test data
    """
    yield relations.fiscalYears_relation()


@pytest.fixture(scope='session')
def annualStatistics_relation():
    """Creates a dataframe that can be loaded into the `annualStatistics` relation.
    
    Yields:
        dataframe: a relation of test data
    """
    yield relations.annualStatistics_relation()


@pytest.fixture(scope='session')
def vendors_relation():
    """Creates a dataframe that can be loaded into the `vendors` relation.
    
    Yields:
        dataframe: a relation of test data
    """
    yield relations.vendors_relation()


@pytest.fixture(scope='session')
def vendorNotes_relation():
    """Creates a dataframe that can be loaded into the `vendorNotes` relation.
    
    Yields:
        dataframe: a relation of test data
    """
    yield relations.vendorNotes_relation()


@pytest.fixture(scope='session')
def statisticsSources_relation():
    """Creates a dataframe that can be loaded into the `statisticsSources` relation.
    
    Yields:
        dataframe: a relation of test data
    """
    yield relations.statisticsSources_relation()


@pytest.fixture(scope='session')
def statisticsSourceNotes_relation():
    """Creates a dataframe that can be loaded into the `statisticsSourceNotes` relation.
    
    Yields:
        dataframe: a relation of test data
    """
    yield relations.statisticsSourceNotes_relation()


@pytest.fixture(scope='session')
def resourceSources_relation():
    """Creates a dataframe that can be loaded into the `resourceSources` relation.
    
    Yields:
        dataframe: a relation of test data
    """
    yield relations.resourceSources_relation()


@pytest.fixture(scope='session')
def resourceSourceNotes_relation():
    """Creates a dataframe that can be loaded into the `resourceSourceNotes` relation.
    
    Yields:
        dataframe: a relation of test data
    """
    yield relations.resourceSourceNotes_relation()


@pytest.fixture(scope='session')
def statisticsResourceSources_relation():
    """Creates a series that can be loaded into the `statisticsResourceSources` relation.
    
    Yields:
        dataframe: a relation of test data
    """
    yield relations.statisticsResourceSources_relation()


@pytest.fixture(scope='session')
def annualUsageCollectionTracking_relation():
    """Creates a dataframe that can be loaded into the `annualUsageCollectionTracking` relation.
    
    Yields:
        dataframe: a relation of test data
    """
    yield relations.annualUsageCollectionTracking_relation()


@pytest.fixture(scope='session')
def workbook_0_2017_relation():
    """Creates a dataframe of test data based on the COUNTER data in the `0_2017.xlsx` workbook.
    
    Yields:
        dataframe: a relation of test data
    """
    yield relations.workbook_0_2017_relation()


@pytest.fixture(scope='session')
def workbook_1_2017_relation():
    """Creates a dataframe of test data based on the COUNTER data in the `1_2017.xlsx` workbook.
    
    Yields:
        dataframe: a relation of test data
    """
    yield relations.workbook_1_2017_relation()


@pytest.fixture(scope='session')
def workbook_2_2017_relation():
    """Creates a dataframe of test data based on the COUNTER data in the `2_2017.xlsx` workbook.
    
    Yields:
        dataframe: a relation of test data
    """
    yield relations.workbook_2_2017_relation()


@pytest.fixture(scope='session')
def workbook_0_2018_relation():
    """Creates a dataframe of test data based on the COUNTER data in the `0_2018.xlsx` workbook.
    
    Yields:
        dataframe: a relation of test data
    """
    yield relations.workbook_0_2018_relation()


@pytest.fixture(scope='session')
def workbook_1_2018_relation():
    """Creates a dataframe of test data based on the COUNTER data in the `1_2018.xlsx` workbook.
    
    Yields:
        dataframe: a relation of test data
    """
    yield relations.workbook_1_2018_relation()


@pytest.fixture(scope='session')
def workbook_2_2018_relation():
    """Creates a dataframe of test data based on the COUNTER data in the `2_2018.xlsx` workbook.
    
    Yields:
        dataframe: a relation of test data
    """
    yield relations.workbook_2_2018_relation()


@pytest.fixture(scope='session')
def workbook_0_2019_relation():
    """Creates a dataframe of test data based on the COUNTER data in the `0_2019.xlsx` workbook.
    
    Yields:
        dataframe: a relation of test data
    """
    yield relations.workbook_0_2019_relation()


@pytest.fixture(scope='session')
def workbook_1_2019_relation():
    """Creates a dataframe of test data based on the COUNTER data in the `1_2019.xlsx` workbook.
    
    Yields:
        dataframe: a relation of test data
    """
    yield relations.workbook_1_2019_relation()


@pytest.fixture(scope='session')
def workbook_2_2019_relation():
    """Creates a dataframe of test data based on the COUNTER data in the `2_2019.xlsx` workbook.
    
    Yields:
        dataframe: a relation of test data
    """
    yield relations.workbook_2_2019_relation()


@pytest.fixture(scope='session')
def workbook_3_2019_relation():
    """Creates a dataframe of test data based on the COUNTER data in the `3_2019.xlsx` workbook.
    
    Yields:
        dataframe: a relation of test data
    """
    yield relations.workbook_3_2019_relation()


@pytest.fixture(scope='session')
def workbook_0_2020_relation():
    """Creates a dataframe of test data based on the COUNTER data in the `0_2020.xlsx` workbook.
    
    Yields:
        dataframe: a relation of test data
    """
    yield relations.workbook_0_2020_relation()


@pytest.fixture(scope='session')
def workbook_1_2020_relation():
    """Creates a dataframe of test data based on the COUNTER data in the `1_2020.xlsx` workbook.
    
    Yields:
        dataframe: a relation of test data
    """
    yield relations.workbook_1_2020_relation()


@pytest.fixture(scope='session')
def workbook_2_2020_relation():
    """Creates a dataframe of test data based on the COUNTER data in the `2_2020.xlsx` workbook.
    
    Yields:
        dataframe: a relation of test data
    """
    yield relations.workbook_2_2020_relation()


@pytest.fixture(scope='session')
def workbook_3_2020_relation():
    """Creates a dataframe of test data based on the COUNTER data in the `3_2020.xlsx` workbook.
    
    Yields:
        dataframe: a relation of test data
    """
    yield relations.workbook_3_2020_relation()


@pytest.fixture(scope='session')
def workbooks_and_relations(workbook_0_2017_relation, workbook_1_2017_relation, workbook_2_2017_relation, workbook_0_2018_relation, workbook_1_2018_relation, workbook_2_2018_relation, workbook_0_2019_relation, workbook_1_2019_relation, workbook_2_2019_relation, workbook_3_2019_relation, workbook_0_2020_relation, workbook_1_2020_relation, workbook_2_2020_relation, workbook_3_2020_relation):
    """A dictionary connecting the name of individual workbooks in the `COUNTER_workbooks_for_tests` folder to the relations containing the given workbook's data.

    Args:
        workbook_0_2017_relation (dataframe): a relation of test data
        workbook_1_2017_relation (dataframe): a relation of test data
        workbook_2_2017_relation (dataframe): a relation of test data
        workbook_0_2018_relation (dataframe): a relation of test data
        workbook_1_2018_relation (dataframe): a relation of test data
        workbook_2_2018_relation (dataframe): a relation of test data
        workbook_0_2019_relation (dataframe): a relation of test data
        workbook_1_2019_relation (dataframe): a relation of test data
        workbook_2_2019_relation (dataframe): a relation of test data
        workbook_3_2019_relation (dataframe): a relation of test data
        workbook_0_2020_relation (dataframe): a relation of test data
        workbook_1_2020_relation (dataframe): a relation of test data
        workbook_2_2020_relation (dataframe): a relation of test data
        workbook_3_2020_relation (dataframe): a relation of test data

    Yields:
        dict: key-value pairs of workbook names and fixture names for the data in the given workbook
    """
    yield {
        '0_2017.xlsx': workbook_0_2017_relation,
        '1_2017.xlsx': workbook_1_2017_relation,
        '2_2017.xlsx': workbook_2_2017_relation,
        '0_2018.xlsx': workbook_0_2018_relation,
        '1_2018.xlsx': workbook_1_2018_relation,
        '2_2018.xlsx': workbook_2_2018_relation,
        '0_2019.xlsx': workbook_0_2019_relation,
        '1_2019.xlsx': workbook_1_2019_relation,
        '2_2019.xlsx': workbook_2_2019_relation,
        '3_2019.xlsx': workbook_3_2019_relation,
        '0_2020.xlsx': workbook_0_2020_relation,
        '1_2020.xlsx': workbook_1_2020_relation,
        '2_2020.xlsx': workbook_2_2020_relation,
        '3_2020.xlsx': workbook_3_2020_relation,
    }


@pytest.fixture(scope='session')
def create_COUNTERData_workbook_iterdir_list():
    """A list of pathlib.Path objects for each of the workbooks containing test data.

    The `iterdir()` method, by definition, returns the files in an arbitrary order, but many test functions rely upon both an `iterdir()` method to get all of the workbooks in the `COUNTER_workbooks_for_tests` folder and a specific order of records in a `COUNTERData_relation` fixture compared to the output of the function being tested. To keep the arbitrary order of `iterdir()` from causing problems, this fixture runs the method once for a test session; the order of workbooks returned in this fixture is used throughout the test session.

    Yields:
        list: the results of `iterdir()` on the `COUNTER_workbooks_for_tests` folder
    """
    yield [file for file in Path(TOP_NOLCAT_DIRECTORY, 'tests', 'bin', 'COUNTER_workbooks_for_tests').iterdir()]


@pytest.fixture
def COUNTERData_relation(create_COUNTERData_workbook_iterdir_list, workbooks_and_relations):
    """Creates a dataframe containing all the test COUNTER data.

    The order in which the the data from the workbook fixtures is added to the dataframe is determined by the `create_COUNTERData_workbook_iterdir_list()` fixture because the dataframes this fixture is being compared against use that same order.

    Args:
        create_COUNTERData_workbook_iterdir_list (list): the results of `iterdir()` on the `COUNTER_workbooks_for_tests` folder
        workbooks_and_relations (dict): key-value pairs of workbook names and fixture names for the data in the given workbook

    Yields:
        dataframe: a relation of test data
    """
    df = pd.concat([workbooks_and_relations[file.name] for file in create_COUNTERData_workbook_iterdir_list], ignore_index=True)
    df.index.name = "COUNTER_data_ID"  # To restore the index name
    yield df


#Section: Fixtures for File I/O
@pytest.fixture(scope='session')
def download_destination():
    """Provides the path to the folder all downloads will go to.

    Ideally, tests would download files to the host machine just like the web app, but at this time, there is no way for pytest tests running in a container on an AWS EC2 instance to interact with the host machine's file system.
    
    Yields:
        pathlib.Path: a path to the destination for downloaded files
    """
    '''#ToDo: If method for interacting with host workstation's file system can be established
    if os.name == 'nt':  # Windows
        yield Path(os.getenv('USERPROFILE')) / 'Downloads'
    else:  # *Nix systems, including macOS
        yield Path(os.getenv('HOME')) / 'Downloads'
    '''
    folder_path = TOP_NOLCAT_DIRECTORY / 'tests' / 'downloads'
    if not folder_path.is_dir():
        folder_path.mkdir()
    yield folder_path


@pytest.fixture(params=[
    TOP_NOLCAT_DIRECTORY / 'tests' / 'data' / 'R5_COUNTER_JSONs_for_tests',
    TOP_NOLCAT_DIRECTORY / 'tests' / 'bin' / 'sample_COUNTER_R4_reports',
])
def path_to_sample_file(request):
    """A parameterized function returning absolute paths to randomly selected files for use in testing file I/O operations.

    This fixture uses parameterization to randomly select multiple files of different types for use in any tests involving file uploads or downloads. The `sample_COUNTER_R4_reports` folder is used for binary data because all of the files within are under 30KB; there is no similar way to limit the file size for text data, as the files in `COUNTER_JSONs_for_tests` can be over 6,000KB.

    Args:
        request (pathlib.Path): an absolute path to a folder with test data

    Yields:
        pathlib.Path: an absolute file path to a randomly selected file
    """
    file_path = request.param
    file_name = choice([file.name for file in file_path.iterdir()])
    file_path_and_name = file_path / file_name
    log.info(f"`path_to_sample_file()` yields {file_path_and_name} (type {type(file_path_and_name)}).")
    yield file_path_and_name


@pytest.fixture
def remove_file_from_S3(path_to_sample_file):
    """Removes a file loaded into S3.

    The yield is a null value as no data is needed from it; the teardown operations using the previously determined file name is the primary purpose of this fixture.

    Args:
        path_to_sample_file (pathlib.Path): an absolute file path to a randomly selected file

    Yields:
        None
    """
    log.debug(fixture_variable_value_declaration_statement("path_to_sample_file", path_to_sample_file))
    yield None
    try:
        s3_client.delete_object(
            Bucket=BUCKET_NAME,
            Key=PATH_WITHIN_BUCKET_FOR_TESTS + path_to_sample_file.name
        )
    except botocore.exceptions as error:
        log.error(unable_to_delete_test_file_in_S3_statement(path_to_sample_file.name, error))


@pytest.fixture
def non_COUNTER_AUCT_object_before_upload(engine, caplog, path_to_sample_file):
    """Creates an `AnnualUsageCollectionTracking` object from a randomly selected record where a non-COUNTER usage file could be but has not yet been uploaded.

    Both the test functions that call this fixture upload files to S3 with names based off of data from this fixture, so removing those files also requires data from this fixture. As a result, the teardown functionality that removes the files from S3 is in this fixture function.

    Args:
        engine (sqlalchemy.engine.Engine): a SQLAlchemy engine
        caplog (pytest.logging.caplog): changes the logging capture level of individual test modules during test runtime
        path_to_sample_file (pathlib.Path): an absolute file path to a randomly selected file
    
    Yields:
        nolcat.models.AnnualUsageCollectionTracking: an AnnualUsageCollectionTracking object corresponding to a record which can have a non-COUNTER usage file uploaded
    """
    caplog.set_level(logging.INFO, logger='nolcat.app')  # For `query_database()`
    record = query_database(
        query=f"""
            SELECT * FROM annualUsageCollectionTracking WHERE
                usage_is_being_collected=true AND
                is_COUNTER_compliant=false AND
                collection_status='Collection not started' AND
                usage_file_path IS NULL;
        """,
        engine=engine,
        # Conversion to class object easier when primary keys stay as standard fields
    )
    if isinstance(record, str):
        pytest.skip(database_function_skip_statements(record, False))
    record = record.sample().reset_index()
    yield_object = AnnualUsageCollectionTracking(
        AUCT_statistics_source=record.at[0,'AUCT_statistics_source'],
        AUCT_fiscal_year=record.at[0,'AUCT_fiscal_year'],
        usage_is_being_collected=record.at[0,'usage_is_being_collected'],
        manual_collection_required=record.at[0,'manual_collection_required'],
        collection_via_email=record.at[0,'collection_via_email'],
        is_COUNTER_compliant=record.at[0,'is_COUNTER_compliant'],
        collection_status=record.at[0,'collection_status'],
        usage_file_path=record.at[0,'usage_file_path'],
        notes=record.at[0,'notes'],
    )
    log.info(initialize_relation_class_object_statement("StatisticsSources", yield_object))
    yield yield_object
    file_name = f"{yield_object.AUCT_statistics_source}_{yield_object.AUCT_fiscal_year}{path_to_sample_file.suffix}"
    try:
        s3_client.delete_object(
            Bucket=BUCKET_NAME,
            Key=PATH_WITHIN_BUCKET_FOR_TESTS + file_name
        )
    except botocore.exceptions as error:
        log.error(unable_to_delete_test_file_in_S3_statement(file_name, error))


@pytest.fixture
def non_COUNTER_AUCT_object_after_upload(engine, caplog):
    """Creates an `AnnualUsageCollectionTracking` object from a randomly selected record where a non-COUNTER usage file has been uploaded.

    Because the `AnnualUsageCollectionTracking.upload_nonstandard_usage_file()` method is what adds values to the `annualUsageCollectionTracking.usage_file_path` field/attribute, only a record where that method has run will have a non-null record/attribute.

    Args:
        engine (sqlalchemy.engine.Engine): a SQLAlchemy engine
        caplog (pytest.logging.caplog): changes the logging capture level of individual test modules during test runtime

    Yields:
        nolcat.models.AnnualUsageCollectionTracking: an AnnualUsageCollectionTracking object corresponding to a record with a non-null `usage_file_path` attribute
    """
    caplog.set_level(logging.INFO, logger='nolcat.app')  # For `query_database()`
    record = query_database(
        query=f"SELECT * FROM annualUsageCollectionTracking WHERE usage_file_path IS NOT NULL;",  # For both records loaded via `test_bp_initialization` and the initialization test data file, all values for `usage_file_path` other than the file names appear as null in the MySQL CLI
        engine=engine,
        # Conversion to class object easier when primary keys stay as standard fields
    )
    if isinstance(record, str):
        pytest.skip(database_function_skip_statements(record, False))
    record = record.sample().reset_index()
    yield_object = AnnualUsageCollectionTracking(
        AUCT_statistics_source=record.at[0,'AUCT_statistics_source'],
        AUCT_fiscal_year=record.at[0,'AUCT_fiscal_year'],
        usage_is_being_collected=record.at[0,'usage_is_being_collected'],
        manual_collection_required=record.at[0,'manual_collection_required'],
        collection_via_email=record.at[0,'collection_via_email'],
        is_COUNTER_compliant=record.at[0,'is_COUNTER_compliant'],
        collection_status=record.at[0,'collection_status'],
        usage_file_path=record.at[0,'usage_file_path'],
        notes=record.at[0,'notes'],
    )
    log.info(initialize_relation_class_object_statement("AnnualUsageCollectionTracking", yield_object))
    yield yield_object


@pytest.fixture
def non_COUNTER_file_to_download_from_S3(path_to_sample_file, non_COUNTER_AUCT_object_after_upload, download_destination):
    """Creates a file in S3 with a name matching the convention in `AnnualUsageCollectionTracking.upload_nonstandard_usage_file()` that can be downloaded when testing `AnnualUsageCollectionTracking.download_nonstandard_usage_file()`.

    Args:
        path_to_sample_file (pathlib.Path): an absolute file path to a randomly selected file
        non_COUNTER_AUCT_object_after_upload (nolcat.models.AnnualUsageCollectionTracking): an AnnualUsageCollectionTracking object corresponding to a record with a non-null `usage_file_path` attribute

    Yields:
        pathlib.Path: an absolute file path to a randomly selected file with a copy temporarily uploaded to S3
    """
    log.debug(fixture_variable_value_declaration_statement("non_COUNTER_AUCT_object_after_upload", non_COUNTER_AUCT_object_after_upload))
    log.debug(file_IO_statement(non_COUNTER_AUCT_object_after_upload.usage_file_path, f"file location {path_to_sample_file.resolve()}", f"S3 location `{BUCKET_NAME}/{PATH_WITHIN_BUCKET_FOR_TESTS}`"))
    logging_message = upload_file_to_S3_bucket(
        path_to_sample_file,
        non_COUNTER_AUCT_object_after_upload.usage_file_path,
        bucket_path=PATH_WITHIN_BUCKET_FOR_TESTS,
    )
    log.debug(logging_message)
    if not upload_file_to_S3_bucket_success_regex().fullmatch(logging_message):
        pytest.skip(failed_upload_to_S3_statement(non_COUNTER_AUCT_object_after_upload.usage_file_path, logging_message))
    yield path_to_sample_file
    try:
        s3_client.delete_object(
            Bucket=BUCKET_NAME,
            Key=PATH_WITHIN_BUCKET_FOR_TESTS + non_COUNTER_AUCT_object_after_upload.usage_file_path,
        )
    except botocore.exceptions as error:
        log.error(unable_to_delete_test_file_in_S3_statement(non_COUNTER_AUCT_object_after_upload.usage_file_path, error))
    Path(download_destination / non_COUNTER_AUCT_object_after_upload.usage_file_path).unlink(missing_ok=True)


#Section: Other Fixtures Used in Multiple Test Modules
@pytest.fixture
def header_value():
    """A dictionary containing a HTTP request header that makes the URL request appear to come from a Chrome browser and not the requests module; some platforms return 403 errors with the standard requests header.
    
    Yields:
        dict: HTTP header data
    """
    yield {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.76 Safari/537.36'}


@pytest.fixture(scope='session')
def most_recent_month_with_usage():
    """Creates `begin_date` and `end_date` SUSHI parameter values representing the most recent month with available data.

    Many methods and functions call the `SUSHICallAndResponse.make_SUSHI_call()` method, so proper testing requires making a SUSHI call; for the PR, DR, TR, and IR, the call requires dates. As the most recent month with usage is unlikely to raise any errors, cause a problem with the check for previously loaded data, or return an overly large amount of data, its first and last day are used in the SUSHI API call. The two dates are returned together in a tuple and separated in the test function with index operators.

    Yields:
        tuple: two datetime.date values, representing the first and last day of a month respectively
    """
    current_date = date.today()
    if current_date.day < 15:
        begin_month = current_date + relativedelta(months=-2)
        begin_date = begin_month.replace(day=1)
    else:
        begin_month = current_date + relativedelta(months=-1)
        begin_date = begin_month.replace(day=1)
    
    end_date = last_day_of_month(begin_date)
    log.info(f"`most_recent_month_with_usage()` yields `begin_date` {begin_date} (type {type(begin_date)}) and `end_date` {end_date} (type {type(end_date)}).")
    yield (begin_date, end_date)


#Section: Test Helper Functions Not Possible in `nolcat.app`
def match_direct_SUSHI_harvest_result(engine, number_of_records, caplog):
    """A test helper function (used because fixture functions cannot take arguments in the test function) transforming the records most recently loaded into the `COUNTERData` relation into a dataframe like that produced by the `StatisticsSources._harvest_R5_SUSHI()` method.

    Tests of functions that load SUSHI data into the database cannot be readily compared against static data; instead, they're compared against the results of the `StatisticsSources._harvest_R5_SUSHI()` method, the underlying part of the function being tested which makes the API call and converts the result into a dataframe. That method's result, however, doesn't exactly match the contents of what's in the `COUNTERData` relation; this helper function pulls the matching number of records out of that relation and modifies the resulting dataframe so it matches the output of the `StatisticsSources._harvest_R5_SUSHI()` method. This function's call of a class method from `nolcat.models` means it can't be initialized in `nolcat.app`.

    Args:
        engine (sqlalchemy.engine.Engine): a SQLAlchemy engine
        number_of_records (int): the number of records in the SUSHI pull
        caplog (pytest.logging.caplog): changes the logging capture level of individual test modules during test runtime
    
    Returns:
        dataframe: the records from `COUNTERData` formatted as if from the `StatisticsSources._harvest_R5_SUSHI()` method
    """
    caplog.set_level(logging.INFO, logger='nolcat.app')  # For `query_database()`
    df = query_database(
        query=f"""
            SELECT *
            FROM (
                SELECT * FROM COUNTERData
                ORDER BY COUNTER_data_ID DESC
                LIMIT {number_of_records}
            ) subquery
            ORDER BY COUNTER_data_ID ASC;
        """,
        engine=engine,
    )
    if isinstance(df, str):
        pytest.skip(database_function_skip_statements(df, False))
    df = df.drop(columns='COUNTER_data_ID')
    df = df[[field for field in df.columns if df[field].notnull().any()]]  # The list comprehension removes fields containing entirely null values
    df = df.astype({k: v for (k, v) in COUNTERData.state_data_types().items() if k in df.columns.tolist()})
    if 'publication_date' in df.columns.tolist():
        df["publication_date"] = pd.to_datetime(
            df["publication_date"],
            errors='coerce',  # Changes the null values to the date dtype's null value `NaT`
        )
    if 'parent_publication_date' in df.columns.tolist():
        df["parent_publication_date"] = pd.to_datetime(
            df["parent_publication_date"],
            errors='coerce',  # Changes the null values to the date dtype's null value `NaT`
        )
    if 'report_creation_date' in df.columns.tolist():
        df["report_creation_date"] = pd.to_datetime(df["report_creation_date"])
    df["usage_date"] = pd.to_datetime(df["usage_date"])
    if df.shape[0] > 20:
        log.info(f"`match_direct_SUSHI_harvest_result()` yields (type {type(df)}):\n{df.head(10)}\n...\n{df.tail(10)}")
    else:
        log.info(f"`match_direct_SUSHI_harvest_result()` yields (type {type(df)}):\n{df}")
    return df


def COUNTER_reports_offered_by_statistics_source(statistics_source_name, URL, credentials):
    """A test helper function (used because fixture functions cannot take arguments in the test function) generating a list of all the customizable reports offered by the given statistics source.

    Args:
        statistics_source_name (str): the name of the statistics source
        URL (str): the base URL for the SUSHI API call
        credentials (dict): the SUSHI credentials for the API call
    
    Returns:
        list: the uppercase abbreviation of all the customizable COUNTER R5 reports offered by the given statistics source
    """
    response = SUSHICallAndResponse(
        statistics_source_name,
        URL,
        "reports",
        credentials,
    ).make_SUSHI_call(bucket_path=PATH_WITHIN_BUCKET_FOR_TESTS)
    if isinstance(response[0], str):
        pytest.skip(f"The SUSHI call for the list of reports raised the error {response[0]}.")
    log.info(successful_SUSHI_call_statement("reports", statistics_source_name))
    response_as_list = [report for report in list(response[0].values())[0]]
    list_of_reports = []
    for report in response_as_list:
        if "Report_ID" in list(report.keys()):
            if isinstance(report["Report_ID"], str) and re.fullmatch(r"[PpDdTtIi][Rr]", report["Report_ID"]):
                list_of_reports.append(report["Report_ID"].upper())
    log.info(f"`COUNTER_reports_offered_by_statistics_source()` for {URL} yields {list_of_reports} (type {type(list_of_reports)}).")
    return list_of_reports


def prepare_HTML_page_for_comparison(page_data):
    """A test helper function (used because fixture functions cannot take arguments in the test function) changing raw binary data with HTML character references into a Unicode string.

    Args:
        page_data (bytes): the content of a page returned by a HTTP request

    Returns:
        str: the page content as a Unicode string
    """
    log.info(f"`page_data` is:\n{page_data}")
    return html.unescape(str(page_data))[2:-1]  # `html.unescape()` returns a string including the bytes indicator and the opening and closing quotes


#Section: Replacement Classes
class _fileAttribute:
    """Enables the `_file` attribute of the `mock_FileStorage_object.stream` attribute.

    Attributes:
        self._file (str): The absolute file path for the COUNTER report being uploaded
    """
    def __init__(self, file_path):
        """The constructor method for `_fileAttribute`, which instantiates the string of the absolute file path for the COUNTER report being uploaded."""
        self._file = str(file_path)


class mock_FileStorage_object:
    """A replacement for a Werkzeug FileStorage object.

    Some class constructors, functions, and methods use an individual or a list of Werkzeug FileStorage objects--the `data` attribute of a WTForms FileField or MultipleFileField object respectively--as an argument. When a list of Werkzeug FileStorage object(s) created with the FileStorage constructor in a fixture is used, however, the _io.BytesIO object returned by the `.stream._file` attribute often raises a `File is not a zip file` error in OpenPyXL's `load_workbook()` function. With the same files encapsulated in the same classes raising an error depending on their source, it could not be determined how to prevent the FileStorage object(s) created in the fixture from raising the error. As an alternative, this class was created; it has the attributes of the Werkzeug FileStorage object needed for the tests its used in, so it works the same way in the method, but it features the absolute file path as a string instead of a _io.BytesIO object to avoid the `File is not a zip file` error.

    Attributes:
        self.stream (_fileAttribute._file): The intermediary attribute for the absolute file path for the COUNTER report being uploaded
        self.filename (str): The name of the file of the COUNTER report being uploaded
    """
    def __init__(self, file_path):
        """The constructor method for `mock_FileStorage_object`, which instantiates the attributes `stream` and `filename` based on the absolute file path for the COUNTER report being uploaded.

        Args:
            file_path (pathlib.Path): The absolute file path for the COUNTER report being uploaded
        """
        self.stream = _fileAttribute(file_path.absolute())
        self.filename = file_path.name


    def __repr__(self):
        """The printable representation of a `mock_FileStorage_object` instance."""
        return f"<__main__.mock_FileStorage_object {{'stream._file': '{self.stream._file}', 'filename': '{self.filename}'}}>"